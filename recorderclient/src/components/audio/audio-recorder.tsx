"use client"

import type React from "react"

import { useState, useRef, useEffect, useCallback } from "react"
import { Upload, Mic, Square, Play, Pause, Save, Trash2, PlusCircle, X, Maximize2, Minimize2, ChevronDown, ChevronUp, Grid, List, ArrowUpDown, ArrowDown, ArrowUp, Unlink, Copy } from "lucide-react"
import { Button } from "@/components/ui/button"
import { Card, CardContent, CardFooter } from "@/components/ui/card"
import { Tabs, TabsContent, TabsList, TabsTrigger } from "@/components/ui/tabs"
import { Select, SelectContent, SelectItem, SelectTrigger, SelectValue } from "@/components/ui/select"
import { transcribeAudio, summarizeText, analyzeText, translateText } from "@/lib/api-client"
import { toast } from "sonner"
import { useDatabase } from '@/hooks/useDatabase'
import {
  AlertDialog,
  AlertDialogAction,
  AlertDialogCancel,
  AlertDialogContent,
  AlertDialogDescription,
  AlertDialogFooter,
  AlertDialogHeader,
  AlertDialogTitle,
} from "@/components/ui/alert-dialog"
import {
  Dialog,
  DialogContent,
  DialogHeader,
  DialogTitle,
  DialogClose,
} from "@/components/ui/dialog"

interface AudioRecorderProps {
  isAuthenticated: boolean;
  onResultsChange?: (results: Array<{ id: number; type: string; content: string; title?: string; generating: boolean; date?: string; originalId?: string }>) => void;
  initialResults?: Array<{ id: number; type: string; content: string; title?: string; generating: boolean; date?: string; originalId?: string }>;
}

export default function AudioRecorder({ isAuthenticated = false, onResultsChange, initialResults = [] }: AudioRecorderProps) {
  // Basic state
  const [isRecording, setIsRecording] = useState(false)
  const [audioURL, setAudioURL] = useState<string | null>(null)
  const [recordingTime, setRecordingTime] = useState(0)
  const [isPlaying, setIsPlaying] = useState(false)
  const [uploadedFile, setUploadedFile] = useState<File | null>(null)
  const [uploadedAudioURL, setUploadedAudioURL] = useState<string | null>(null)
  const [isUploadedPlaying, setIsUploadedPlaying] = useState(false)
  const [isPostRecording, setIsPostRecording] = useState(false)
  const [selectedAiAction, setSelectedAiAction] = useState<string>("summarize")
  const [aiProcessing, setAiProcessing] = useState(false)
  const [currentMimeType, setCurrentMimeType] = useState<string>("")
  const [processedResults, setProcessedResults] = useState<Array<{ id: number; type: string; content: string; title?: string; generating: boolean; expanded?: boolean; date?: string; originalId?: string }>>(initialResults);
  const [isMinimized, setIsMinimized] = useState<boolean>(false);
  const [lastTranscriptionId, setLastTranscriptionId] = useState<string | null>(null);
  // View mode state
  const [viewMode, setViewMode] = useState<"card" | "list">("card");
  // Sort direction state
  const [sortDirection, setSortDirection] = useState<"asc" | "desc">("desc");
  
  // Delete confirmation dialog state
  const [deleteDialogOpen, setDeleteDialogOpen] = useState(false);
  const [itemToDelete, setItemToDelete] = useState<{ id: number; type: string; originalId: string | null }>({ id: 0, type: '', originalId: null });
  
  // Transcript removal confirmation dialog state
  const [transcriptRemovalDialogOpen, setTranscriptRemovalDialogOpen] = useState(false);
  const [transcriptToRemove, setTranscriptToRemove] = useState<{ analysisId: string; resultId: number }>({ analysisId: '', resultId: 0 });
  
  // Modal state for expanded card
  const [modalOpen, setModalOpen] = useState(false);
  const [selectedCard, setSelectedCard] = useState<{ 
    id: number; 
    type: string; 
    content: string; 
    title?: string; 
    date?: string;
    originalId?: string;
  } | null>(null);
  
  // Recording time limit in seconds based on auth status
  const recordingTimeLimit = isAuthenticated ? 600 : 300;
  
  // Add a state for the transcript
  const [transcriptContent, setTranscriptContent] = useState<string>(
    "This is a simulated transcript of your audio recording. It would contain all the spoken words detected in your recording. In a real implementation, this would be generated by a speech-to-text service.\n\nThe transcript would be formatted with paragraphs and punctuation to make it easy to read. It might also include timestamps or speaker identification depending on the service used.",
  )

  // Refs
  const mediaRecorderRef = useRef<MediaRecorder | null>(null)
  const audioChunksRef = useRef<Blob[]>([])
  const audioRef = useRef<HTMLAudioElement | null>(null)
  const timerRef = useRef<NodeJS.Timeout | null>(null)
  const uploadedAudioRef = useRef<HTMLAudioElement | null>(null)
  const canvasRef = useRef<HTMLCanvasElement | null>(null)
  const animationFrameRef = useRef<number | null>(null)
  const analyzerRef = useRef<AnalyserNode | null>(null)
  const micStreamRef = useRef<MediaStream | null>(null)
  const fileInputRef = useRef<HTMLInputElement | null>(null)
  
  // Map to store transcription content for each result
  const [transcriptMap, setTranscriptMap] = useState<Record<number, string>>({});
  // Convert lastTranscriptionId to a numeric ID for use with the transcript map
  const [lastTranscriptionNumericId, setLastTranscriptionNumericId] = useState<number | null>(null);

  // Map to store original IDs for each result
  const [originalIdMap, setOriginalIdMap] = useState<Record<number, string>>({});
  
  // Translation state
  const [translatedContent, setTranslatedContent] = useState<string>("");
  const [isTranslating, setIsTranslating] = useState<boolean>(false);
  const [selectedLanguage, setSelectedLanguage] = useState<string>("english");
  const [translatedTitle, setTranslatedTitle] = useState<string>("");
  const [translationId, setTranslationId] = useState<string | null>(null);
  const [copySuccess, setCopySuccess] = useState<boolean>(false);

  // Initialize transcriptMap from initialResults
  useEffect(() => {
    if (initialResults.length > 0) {
      console.log('AudioRecorder - Initializing transcript map from initialResults');
      const newTranscriptMap: Record<number, string> = {};
      
      initialResults.forEach(result => {
        if (result.type === 'transcribe') {
          console.log(`AudioRecorder - Adding transcription to map: ID=${result.id}, Content=${result.content ? result.content.substring(0, 50) + '...' : 'No content'}`);
          newTranscriptMap[result.id] = result.content;
        }
      });
      
      console.log('AudioRecorder - New transcript map:', Object.keys(newTranscriptMap).length, 'entries');
      setTranscriptMap(newTranscriptMap);
      
      // Also update processedResults to ensure they have the content
      setProcessedResults(initialResults.map(result => ({
        ...result,
        // Ensure expanded is set to false initially
        expanded: false
      })));
    }
  }, [initialResults]);

  // Update lastTranscriptionNumericId when lastTranscriptionId changes
  useEffect(() => {
    if (lastTranscriptionId) {
      // Convert UUID to numeric ID using the same method as in AudioWrapper
      const numericId = parseInt(lastTranscriptionId.replace(/-/g, '').substring(0, 13), 16);
      console.log('AudioRecorder - Setting lastTranscriptionNumericId:', numericId);
      setLastTranscriptionNumericId(numericId);
    }
  }, [lastTranscriptionId]);

  // Function to get transcript content for a specific result
  const getTranscriptContent = (resultId: number) => {
    // First check if it's in the map
    if (transcriptMap[resultId]) {
      console.log(`AudioRecorder - Using stored transcript for result ID ${resultId}:`, 
        typeof transcriptMap[resultId] === 'string' && transcriptMap[resultId].length > 50 
          ? transcriptMap[resultId].substring(0, 50) + '...'
          : transcriptMap[resultId]
      );
      return transcriptMap[resultId];
    }
    
    // If not in map, check if it's in the processedResults
    const result = processedResults.find(r => r.id === resultId);
    if (result && result.type === 'transcribe' && result.content) {
      console.log(`AudioRecorder - Found transcript in processedResults for ID ${resultId}:`, 
        result.content.length > 50 ? result.content.substring(0, 50) + '...' : result.content
      );
      
      // Add it to the map for future use
      setTranscriptMap(prevMap => ({
        ...prevMap,
        [resultId]: result.content
      }));
      
      return result.content;
    }
    
    // If there's no content yet but we have an originalId from the result
    if (result && result.originalId) {
      console.log(`AudioRecorder - No content in map, but have originalId for ${resultId}: ${result.originalId}`);
      
      // Set a loading message in the map
      setTranscriptMap(prevMap => ({
        ...prevMap,
        [resultId]: "Loading transcript from database..."
      }));
      
      // For summaries and analyses, we need to get the transcription via the analysis record
      if (result.type === 'summarize' || result.type === 'analyze') {
        console.log(`AudioRecorder - Fetching transcript for analysis ID ${result.originalId}`);
        // Start fetching in the background
        fetchTranscriptionForAnalysis(result.originalId, resultId)
          .then(content => {
            if (content) {
              setTranscriptMap(prevMap => ({
                ...prevMap,
                [resultId]: content
              }));
            }
          });
      } else {
        // For direct transcriptions
        console.log(`AudioRecorder - Fetching transcript from DB for transcription ID ${result.originalId}`);
        // Start fetching in the background
        fetchTranscriptionFromDB(result.originalId, resultId)
          .then(content => {
            if (content) {
              setTranscriptMap(prevMap => ({
                ...prevMap,
                [resultId]: content
              }));
            }
          });
      }
      
      return "Loading transcript from database...";
    }
    
    // If we have a lastTranscriptionId but no content yet, fetch from DB
    if (lastTranscriptionId) {
      // Start fetching from DB if not already started
      console.log(`AudioRecorder - No content, but have lastTranscriptionId: ${lastTranscriptionId}`);
      
      // Set a loading message in the map
      setTranscriptMap(prevMap => ({
        ...prevMap,
        [resultId]: "Loading transcript from database..."
      }));
      
      fetchTranscriptionFromDB(lastTranscriptionId, resultId)
        .then(content => {
          if (content) {
            setTranscriptMap(prevMap => ({
              ...prevMap,
              [resultId]: content
            }));
          }
        });
      
      return "Loading transcript from database...";
    }
    
    return "No transcript available";
  };
  
  // Visualization state for the recording button
  const [audioLevel, setAudioLevel] = useState<number>(0)
  const visualizationIntervalRef = useRef<NodeJS.Timeout | null>(null)
  
  // Add the useDatabase hook
  const { 
    uploadFile, 
    createTranscription, 
    createAnalysis,
    deleteTranscription,
    deleteAnalysis,
    getTranscription,
    getAnalysis,
    removeTranscriptionReference,
    isLoading: dbLoading, 
    error: databaseError,
    createTranslation,
    getTranslation,
    updateTranslation
  } = useDatabase();
  
  // Effect to check if recording time has reached the limit
  useEffect(() => {
    if (isRecording && recordingTime >= recordingTimeLimit) {
      stopRecording();
      
      // Show toast notification
      if (isAuthenticated) {
        toast.warning("Recording limit reached", {
          description: "You've reached the 10-minute recording limit."
        });
      } else {
        toast.warning("Recording limit reached", {
          description: "You've reached the 5-minute recording limit. Sign in for longer recordings."
        });
      }
    }
  }, [isRecording, recordingTime, recordingTimeLimit, isAuthenticated]);
  
  // Calculate time remaining in seconds
  const timeRemainingSeconds = recordingTimeLimit - recordingTime;
  
  // Format time remaining for display
  const formatTimeRemaining = () => {
    const mins = Math.floor(timeRemainingSeconds / 60);
    const secs = timeRemainingSeconds % 60;
    return `${mins}:${secs < 10 ? "0" : ""}${secs}`;
  };
  
  // Clean up resources when component unmounts
  useEffect(() => {
    return () => {
      // Stop any active recording
      if (mediaRecorderRef.current && mediaRecorderRef.current.state === "recording") {
        try {
          mediaRecorderRef.current.stop()
        } catch (e) {
          console.error("Error stopping media recorder:", e)
        }
      }
      
      // Clear timer
      if (timerRef.current) {
        clearInterval(timerRef.current)
      }
      
      // Clear visualization interval
      if (visualizationIntervalRef.current) {
        clearInterval(visualizationIntervalRef.current)
      }
      
      // Stop microphone stream
      if (micStreamRef.current) {
        try {
          micStreamRef.current.getTracks().forEach(track => {
            try {
              track.stop()
            } catch (e) {
              console.error("Error stopping track:", e)
            }
          })
        } catch (e) {
          console.error("Error stopping stream:", e)
        }
      }
      
      // Clean up audio URLs
      if (audioURL) {
        URL.revokeObjectURL(audioURL)
      }
      
      if (uploadedAudioURL) {
        URL.revokeObjectURL(uploadedAudioURL)
      }
    }
  }, [audioURL, uploadedAudioURL])
  
  // Handle audio element events
  useEffect(() => {
    const audioElement = audioRef.current
    
    if (audioElement) {
      const handleEnded = () => {
        console.log("Audio playback ended")
        setIsPlaying(false)
        setIsUploadedPlaying(false)
      }
      
      const handleError = (e: Event) => {
        console.error("Audio element error:", e)
        setIsPlaying(false)
        setIsUploadedPlaying(false)
      }
      
      audioElement.addEventListener('ended', handleEnded)
      audioElement.addEventListener('error', handleError)
      
      return () => {
        audioElement.removeEventListener('ended', handleEnded)
        audioElement.removeEventListener('error', handleError)
      }
    }
  }, [])
  
  // Format time for display
  const formatTime = (seconds: number) => {
    const mins = Math.floor(seconds / 60)
    const secs = seconds % 60
    return `${mins}:${secs < 10 ? "0" : ""}${secs}`
  }
  
  // Start recording
  const startRecording = async () => {
    try {
      console.log("Starting recording...")
      
      // Get microphone stream
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
        }
      })
      
      // Store stream reference
      micStreamRef.current = stream
      
      // Reset chunks array
      audioChunksRef.current = []
      
      // Determine the supported MIME type
      const mimeType = getSupportedMimeType();
      console.log("Using MIME type:", mimeType);
      setCurrentMimeType(mimeType || 'audio/mp4');
      
      // Create media recorder with the supported MIME type
      try {
        const options = mimeType ? { mimeType } : { mimeType: 'audio/mp4' };
        mediaRecorderRef.current = new MediaRecorder(stream, options);
        console.log("MediaRecorder created successfully");
      } catch (error) {
        console.error("Error creating MediaRecorder:", error);
        // Try again without specifying a MIME type
        try {
          console.log("Trying to create MediaRecorder without MIME type");
          mediaRecorderRef.current = new MediaRecorder(stream);
          console.log("MediaRecorder created successfully without MIME type");
          // Get the actual MIME type being used
          if (mediaRecorderRef.current.mimeType) {
            setCurrentMimeType(mediaRecorderRef.current.mimeType);
            console.log("Using browser-selected MIME type:", mediaRecorderRef.current.mimeType);
          } else {
            setCurrentMimeType('audio/mp4'); // Default fallback
          }
        } catch (fallbackError) {
          console.error("Failed to create MediaRecorder even without MIME type:", fallbackError);
          alert("Your browser doesn't support audio recording. Please try a different browser.");
          // Clean up
          if (micStreamRef.current) {
            micStreamRef.current.getTracks().forEach(track => track.stop());
          }
          return;
        }
      }
      
      // Set up event handlers
      mediaRecorderRef.current.ondataavailable = (event) => {
        console.log("Data available:", event.data?.size)
        if (event.data && event.data.size > 0) {
          audioChunksRef.current.push(event.data)
        }
      }
      
      mediaRecorderRef.current.onstop = () => {
        console.log("MediaRecorder stopped, chunks:", audioChunksRef.current.length);
        if (audioChunksRef.current.length === 0) {
          console.warn("No audio data was recorded");
          return;
        }
        try {
          console.log("Creating audio blob with MIME type: audio/mp4");
          const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/mp4' });
          const url = URL.createObjectURL(audioBlob);
          setAudioURL(url);
          console.log("Audio blob created successfully");

          // Start automatic transcription
          setAiProcessing(true);
          (async () => {
            try {
              console.log("Calling transcribeAudio with audio blob");
              const result = await transcribeAudio(audioBlob);
              let transcript = "";
              if (result.success && result.text) {
                transcript = result.text;
                
                // Store the audio file and transcription in the database if user is authenticated
                if (isAuthenticated) {
                  try {
                    // Create a File object from the Blob
                    const file = new File([audioBlob], `recording_${new Date().toISOString()}.mp4`, { 
                      type: 'audio/mp4' 
                    });
                    
                    // Upload the file to Supabase storage
                    const fileData = await uploadFile(file);
                    
                    if (fileData) {
                      // Create a transcription record
                      const transcriptionData = await createTranscription(
                        fileData.id,
                        "Recorded Audio Transcription",
                        transcript,
                        recordingTime, // Pass recordingTime as a number
                        { source: "recorder" }
                      );
                      
                      console.log("Transcription saved to database");
                      
                      // Store the transcription ID for later use with analyses
                      setLastTranscriptionId(transcriptionData?.id || null);
                      
                      // If we have a transcription ID, convert it to a numeric ID and store the transcript in the map
                      if (transcriptionData?.id) {
                        const numericId = parseInt(transcriptionData.id.replace(/-/g, '').substring(0, 13), 16);
                        console.log('Setting transcript in map for ID:', numericId);
                        setTranscriptMap(prevMap => ({
                          ...prevMap,
                          [numericId]: transcript
                        }));
                        
                        // Also store the original ID in the originalIdMap
                        setOriginalIdMap(prevMap => ({
                          ...prevMap,
                          [numericId]: transcriptionData.id
                        }));
                      }
                    }
                  } catch (dbError) {
                    console.error("Error saving to database:", dbError);
                  }
                }
              } else {
                transcript = "Error: " + (result.error || "Unknown transcription error");
              }
              setTranscriptContent(transcript);
            } catch (e) {
              console.error("Error in transcription process:", e);
              setTranscriptContent("Error: " + (e instanceof Error ? e.message : String(e)));
            } finally {
              setAiProcessing(false);
            }
          })();

        } catch (error) {
          console.error("Error creating audio blob:", error);
          // Fallback logic
          try {
            const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/mp4' });
            const url = URL.createObjectURL(audioBlob);
            setAudioURL(url);
            setCurrentMimeType('audio/mp4');
            console.log("Created audio blob with fallback MIME type: audio/mp4");
          } catch (fallbackError) {
            console.error("Failed to create audio blob even with fallback:", fallbackError);
            alert("There was an error processing your recording.");
          }
        }
      }
      
      // Start recording
      mediaRecorderRef.current.start(100) // Capture in 100ms chunks
      
      // Update UI state
      setIsRecording(true)
      setRecordingTime(0)
      setIsPostRecording(false)
      
      // Start timer
      timerRef.current = setInterval(() => {
        setRecordingTime(prev => prev + 1)
      }, 1000)
      
      // Start visualization for the recording button
      startVisualization(stream)
      
      console.log("Recording started successfully")
    } catch (error) {
      console.error("Error starting recording:", error)
    }
  }
  
  // Start visualization for the recording button
  const startVisualization = (stream: MediaStream) => {
    try {
      // Clear any existing visualization interval
      if (visualizationIntervalRef.current) {
        clearInterval(visualizationIntervalRef.current)
      }
      
      // Create audio context and analyzer
      // Define the AudioContext type that includes webkitAudioContext
      type AudioContextType = typeof AudioContext
      
      // Define a type for the window with webkitAudioContext
      interface WindowWithWebkitAudio extends Window {
        webkitAudioContext?: AudioContextType;
      }
      
      const AudioContextClass: AudioContextType = 
        window.AudioContext || (window as WindowWithWebkitAudio).webkitAudioContext || null as unknown as AudioContextType;
      
      const audioContext = new AudioContextClass()
      const analyser = audioContext.createAnalyser()
      analyser.fftSize = 256
      analyser.smoothingTimeConstant = 0.3 // Make it more responsive (lower = more responsive)
      
      // Connect microphone to analyzer
      const source = audioContext.createMediaStreamSource(stream)
      source.connect(analyser)
      
      // Create data array for frequency data
      const dataArray = new Uint8Array(analyser.frequencyBinCount)
      
      // Update visualization at regular intervals
      visualizationIntervalRef.current = setInterval(() => {
        // Get frequency data
        analyser.getByteFrequencyData(dataArray)
        
        // Calculate average level with emphasis on lower frequencies
        // which are more common in speech
        let sum = 0
        let weight = 0
        for (let i = 0; i < dataArray.length; i++) {
          // Give more weight to lower frequencies (first third of the spectrum)
          const frequencyWeight = i < dataArray.length / 3 ? 3 : 1
          sum += dataArray[i] * frequencyWeight
          weight += frequencyWeight
        }
        const avg = sum / weight
        
        // Update audio level (0-100 scale) with smoother transitions
        // Amplify the effect by multiplying the raw value
        setAudioLevel(prev => {
          // Smooth transitions by blending previous and new values
          const amplifiedLevel = Math.min(100, avg * 1.5) // Amplify by 1.5x
          return prev * 0.2 + amplifiedLevel * 0.8 // 80% new value, 20% old value for more responsiveness
        })
      }, 20) // Update 50 times per second for smoother animation
      
      // Clean up when recording stops
      return () => {
        clearInterval(visualizationIntervalRef.current!)
        audioContext.close()
      }
    } catch (error) {
      console.error("Error starting visualization:", error)
    }
  }
  
  // Get dynamic gradient position based on audio level
  const getGradientPosition = () => {
    // Map audio level (0-100) to gradient position (100%-0%)
    // When audio level is high, gradient moves up (lower percentage)
    // When audio level is low, gradient moves down (higher percentage)
    const position = 100 - audioLevel;
    return `${position}%`
  }
  
  // Get button styles for recording button
  const getRecordingButtonStyles = () => {
    // Fixed size for the button
    const size = '4rem';
    
    // Create a dynamic background with gradient that moves based on audio level
    return {
      width: size,
      height: size,
      background: `linear-gradient(to top, #ef4444 ${getGradientPosition()}, #f87171 100%)`,
      boxShadow: `0 0 ${Math.max(5, audioLevel / 5)}px rgba(239, 68, 68, 0.6)`,
      transition: 'box-shadow 0.1s ease-in-out',
    };
  }
  
  // Get button styles for stop button
  const getStopButtonStyles = () => {
    // Fixed size for the button
    const size = '4rem';
    
    // Create a dynamic background with gradient that moves based on audio level
    return {
      width: size,
      height: size,
      background: `linear-gradient(to top, #b91c1c ${getGradientPosition()}, #ef4444 100%)`,
      boxShadow: `0 0 ${Math.max(5, audioLevel / 5)}px rgba(185, 28, 28, 0.6)`,
      transition: 'box-shadow 0.1s ease-in-out',
    };
  }
  
  // Stop recording
  const stopRecording = () => {
    try {
      console.log("Stopping recording...")
      
      // Stop timer
      if (timerRef.current) {
        clearInterval(timerRef.current)
        timerRef.current = null
      }
      
      // Stop visualization
      if (visualizationIntervalRef.current) {
        clearInterval(visualizationIntervalRef.current)
        visualizationIntervalRef.current = null
      }
      
      // Stop media recorder
      if (mediaRecorderRef.current && mediaRecorderRef.current.state === "recording") {
        mediaRecorderRef.current.stop()
      }
      
      // Stop microphone stream
      if (micStreamRef.current) {
        micStreamRef.current.getTracks().forEach(track => track.stop())
        micStreamRef.current = null
      }
      
      // Update UI state
      setIsRecording(false)
      setIsPostRecording(true)
      setAudioLevel(0)
      
      console.log("Recording stopped successfully")
    } catch (error) {
      console.error("Error stopping recording:", error)
      setIsRecording(false)
      setIsPostRecording(true)
    }
  }
  
  // Reset recorder to initial state
  const resetRecorder = () => {
    // Clear previous recording
    if (audioURL) {
      URL.revokeObjectURL(audioURL)
      setAudioURL(null)
    }
    
    // Reset to initial state
    setIsPostRecording(false)
    setIsRecording(false)
    setRecordingTime(0)
    setAiProcessing(false)
    setIsPlaying(false)
    
    // Stop audio playback if it's playing
    if (audioRef.current) {
      audioRef.current.pause();
      audioRef.current.currentTime = 0;
    }
  }
  
  // Handle file upload
  const handleFileUpload = (event: React.ChangeEvent<HTMLInputElement>) => {
    const files = event.target.files
    if (files && files.length > 0) {
      const file = files[0]
      
      // Check if the file is an audio or video file (MP4 files are often identified as video/mp4)
      if (!file.type.startsWith('audio/') && !file.type.startsWith('video/')) {
        alert('Please upload an audio or video file')
        return
      }
      
      console.log("Uploaded file type:", file.type)
      setUploadedFile(file)
      
      // Create a URL for the uploaded file
      const url = URL.createObjectURL(file)
      
      // If we previously had an uploaded file, revoke its URL
      if (uploadedAudioURL) {
        URL.revokeObjectURL(uploadedAudioURL)
      }
      
      setUploadedAudioURL(url)
      setCurrentMimeType('audio/mp4') // Treat all uploads as MP4 for consistency
      
      // Reset any previous recording state
      if (isPostRecording) {
        resetRecorder()
      }
      
      // Start automatic transcription of the uploaded file
      setAiProcessing(true);
      
      // Convert File to Blob for transcription
      (async () => {
        try {
          console.log("Calling transcribeAudio with uploaded file");
          const result = await transcribeAudio(file);
          let transcript = "";
          if (result.success && result.text) {
            transcript = result.text;
            toast.success("Transcription complete", {
              description: "Your uploaded file has been transcribed successfully."
            });
            
            // Store the uploaded file and transcription in the database if user is authenticated
            if (isAuthenticated) {
              try {
                // Upload the file to Supabase storage
                const fileData = await uploadFile(file);
                
                if (fileData) {
                  // We need to set the audio source and wait for metadata to load
                  // to get the duration
                  const getDuration = () => {
                    return new Promise<number>((resolve) => {
                      if (audioRef.current) {
                        // If the audio element already has metadata loaded
                        if (audioRef.current.duration) {
                          resolve(Math.round(audioRef.current.duration));
                        } else {
                          // Wait for metadata to load
                          const handleLoadedMetadata = () => {
                            const duration = Math.round(audioRef.current!.duration);
                            audioRef.current!.removeEventListener('loadedmetadata', handleLoadedMetadata);
                            resolve(duration);
                          };
                          audioRef.current.addEventListener('loadedmetadata', handleLoadedMetadata);
                          audioRef.current.src = url;
                        }
                      } else {
                        resolve(0); // Fallback if no audio element
                      }
                    });
                  };
                  
                  const duration = await getDuration();
                  
                  // Create a transcription record
                  const transcriptionData = await createTranscription(
                    fileData.id,
                    file.name || "Uploaded Audio Transcription",
                    transcript,
                    duration || 0,
                    { source: "upload" }
                  );
                  
                  console.log("Transcription saved to database");
                  
                  // Store the transcription ID for later use with analyses
                  setLastTranscriptionId(transcriptionData?.id || null);
                  
                  // If we have a transcription ID, convert it to a numeric ID and store the transcript in the map
                  if (transcriptionData?.id) {
                    const numericId = parseInt(transcriptionData.id.replace(/-/g, '').substring(0, 13), 16);
                    console.log('Setting transcript in map for ID:', numericId);
                    setTranscriptMap(prevMap => ({
                      ...prevMap,
                      [numericId]: transcript
                    }));
                    
                    // Also store the original ID in the originalIdMap
                    setOriginalIdMap(prevMap => ({
                      ...prevMap,
                      [numericId]: transcriptionData.id
                    }));
                  }
                }
              } catch (dbError) {
                console.error("Error saving uploaded file to database:", dbError);
              }
            }
          } else {
            transcript = "Error: " + (result.error || "Unknown transcription error");
            toast.error("Transcription failed", {
              description: result.error || "Unknown transcription error"
            });
          }
          setTranscriptContent(transcript);
        } catch (e) {
          console.error("Error in transcription process:", e);
          setTranscriptContent("Error: " + (e instanceof Error ? e.message : String(e)));
          toast.error("Transcription failed", {
            description: "An error occurred during transcription."
          });
        } finally {
          setAiProcessing(false);
        }
      })();
    }
  }
  
  // Toggle play recorded audio
  const togglePlayRecorded = () => {
    if (audioRef.current && audioURL) {
      if (isPlaying) {
        audioRef.current.pause()
      } else {
        // Make sure we reset the audio element before setting a new source
        audioRef.current.pause()
        audioRef.current.currentTime = 0
        audioRef.current.src = audioURL
        
        // Add error handling for playback
        const playPromise = audioRef.current.play()
        if (playPromise !== undefined) {
          playPromise.catch(error => {
            console.error("Error playing recorded audio:", error)
            alert("Error playing audio. Please try recording again.")
            setIsPlaying(false)
          })
        }
      }
      setIsPlaying(!isPlaying)
    }
  }
  
  // Toggle play uploaded audio
  const togglePlayUploaded = () => {
    if (audioRef.current && uploadedAudioURL) {
      if (isUploadedPlaying) {
        audioRef.current.pause()
      } else {
        // Make sure we reset the audio element before setting a new source
        audioRef.current.pause()
        audioRef.current.currentTime = 0
        audioRef.current.src = uploadedAudioURL
        
        // Add error handling for playback
        const playPromise = audioRef.current.play()
        if (playPromise !== undefined) {
          playPromise.catch(error => {
            console.error("Error playing uploaded audio:", error)
            alert("Error playing audio. The file format may not be supported.")
            setIsUploadedPlaying(false)
          })
        }
      }
      setIsUploadedPlaying(!isUploadedPlaying)
    }
  }
  
  // Process with AI
  const processWithAI = async () => {
    setAiProcessing(true);
    const newId = new Date().getTime();
    
    // Only add to processedResults for summarize and analyze actions, not for transcripts
    if (selectedAiAction !== "transcribe") {
      // Add a new result card with generating state
      setProcessedResults(prev => [
        ...prev,
        { 
          id: newId, 
          type: selectedAiAction, 
          content: "", 
          title: "", 
          generating: true, 
          expanded: false,
          date: new Date().toISOString() // Add date field
        }
      ]);
    }

    try {
      if (selectedAiAction === "summarize") {
        const result = await summarizeText(transcriptContent);
        
        if (result.success) {
          const content = result.content || result.result || "";
          const title = result.title || "Summary";
          
          // Store the analysis in the database if user is authenticated
          let analysisId = null;
          if (isAuthenticated) {
            try {
              // Use the lastTranscriptionId if available, otherwise use null
              const transcriptionId = lastTranscriptionId || null;
              
              const analysisData = await createAnalysis(
                transcriptionId,
                title,
                content,
                "summary",
                { source: "recorder" }
              );
              
              console.log("Summary saved to database");
              analysisId = analysisData?.id;
            } catch (dbError) {
              console.error("Error saving summary to database:", dbError);
            }
          }
          
          // Update the result card with the generated content and originalId if available
          setProcessedResults(prev => prev.map(item => 
            item.id === newId 
              ? { 
                  ...item, 
                  content, 
                  title, 
                  generating: false,
                  originalId: analysisId
                } 
              : item
          ));
          
          // If we have an analysis ID, store it in the originalIdMap
          if (analysisId) {
            setOriginalIdMap(prevMap => ({
              ...prevMap,
              [newId]: analysisId
            }));
          }
        } else {
          // Handle error
          setProcessedResults(prev => prev.map(item => 
            item.id === newId 
              ? { 
                  ...item, 
                  content: `Error: ${result.error || "Failed to generate summary"}`, 
                  title: "Error", 
                  generating: false 
                } 
              : item
          ));
        }
      } else if (selectedAiAction === "analyze") {
        const result = await analyzeText(transcriptContent);
        
        if (result.success) {
          const content = result.content || result.result || "";
          const title = result.title || "Analysis";
          
          // Store the analysis in the database if user is authenticated
          let analysisId = null;
          if (isAuthenticated) {
            try {
              // Use the lastTranscriptionId if available, otherwise use null
              const transcriptionId = lastTranscriptionId || null;
              
              const analysisData = await createAnalysis(
                transcriptionId,
                title,
                content,
                "analysis",
                { source: "recorder" }
              );
              
              console.log("Analysis saved to database");
              analysisId = analysisData?.id;
            } catch (dbError) {
              console.error("Error saving analysis to database:", dbError);
            }
          }
          
          // Update the result card with the generated content and originalId if available
          setProcessedResults(prev => prev.map(item => 
            item.id === newId 
              ? { 
                  ...item, 
                  content,
                  title,
                  generating: false,
                  originalId: analysisId
                } 
              : item
          ));
          
          // If we have an analysis ID, store it in the originalIdMap
          if (analysisId) {
            setOriginalIdMap(prevMap => ({
              ...prevMap,
              [newId]: analysisId
            }));
          }
        } else {
          // Handle error
          setProcessedResults(prev => prev.map(item => 
            item.id === newId 
              ? { 
                  ...item, 
                  content: `Error: ${result.error || "Failed to generate analysis"}`, 
                  title: "Error", 
                  generating: false 
                } 
              : item
          ));
        }
      } else if (selectedAiAction === "transcribe") {
        // For transcribe, we directly use the transcriptContent
        const content = transcriptContent;
        const title = "Transcription";
        
        // Store the transcription in the database if user is authenticated
        if (isAuthenticated) {
          try {
            // Create a temporary file ID since we don't have a real file
            const tempFileId = "temp-file-" + Date.now();
            
            // Create a transcription record
            const transcriptionData = await createTranscription(
              tempFileId,
              title,
              content,
              recordingTime, // Duration as number
              { source: "recorder", isDirectTranscription: true }
            );
            
            console.log("Transcription saved to database");
            
            // Add the new result to the processed results
            const newResult = {
              id: Date.now(),
              type: selectedAiAction,
              content,
              title,
              generating: false,
              date: new Date().toISOString(),
              originalId: transcriptionData?.id
            };
            
            // Update the lastTranscriptionId
            if (transcriptionData?.id) {
              setLastTranscriptionId(transcriptionData.id);
              setLastTranscriptionNumericId(newResult.id);
              
              // Store the transcript content in the transcriptMap
              setTranscriptMap(prevMap => ({
                ...prevMap,
                [newResult.id]: content
              }));
            }
            
            setProcessedResults(prev => [newResult, ...prev]);
          } catch (dbError) {
            console.error("Error saving transcription to database:", dbError);
          }
        }
      }
    } catch (error) {
      console.error("Error processing with AI:", error);
      
      // Update the result card with the error
      if (selectedAiAction !== "transcribe") {
        setProcessedResults(prev => prev.map(item => 
          item.id === newId 
            ? { 
                ...item, 
                content: `Error: ${error instanceof Error ? error.message : "An unknown error occurred"}`, 
                title: "Error", 
                generating: false 
              } 
            : item
        ));
      }
    } finally {
      setAiProcessing(false);
      
      // Notify parent component of results change
      if (onResultsChange) {
        onResultsChange(processedResults);
      }
    }
  };

  // Helper function to determine the supported MIME type
  const getSupportedMimeType = () => {
    // Only support MP4 format as requested
    if (MediaRecorder.isTypeSupported('audio/mp4')) {
      console.log('Browser supports recording in audio/mp4 format');
      return 'audio/mp4';
    }
    
    console.warn('MP4 format not supported. Using default browser implementation.');
    // Fallback to default (browser will choose)
    return '';
  };

  // Helper function to get file extension from MIME type
  const getFileExtensionFromMimeType = (mimeType: string): string => {
    // Default to mp4 as requested
    if (!mimeType || mimeType.includes('mp4')) return 'mp4';
    if (mimeType.includes('webm')) return 'webm';
    if (mimeType.includes('ogg')) return 'ogg';
    if (mimeType.includes('wav')) return 'wav';
    if (mimeType.includes('mp3') || mimeType.includes('mpeg')) return 'mp3';
    if (mimeType.includes('aac')) return 'aac';
    
    // Default fallback
    return 'mp4';
  };

  // Call onResultsChange when processedResults changes
  useEffect(() => {
    if (onResultsChange) {
      onResultsChange(processedResults);
    }
  }, [processedResults, onResultsChange]);

  // Function to toggle expanded state for a card
  const toggleCardExpanded = (id: number) => {
    console.log(`AudioRecorder - Toggling card expanded state for ID ${id}`);
    
    // Find the card to display in the modal
    const result = processedResults.find(r => r.id === id);
    if (result) {
      setSelectedCard(result);
      setModalOpen(true);
      
      // If it's a transcript card, ensure we have the transcript content
      if (result.type === 'transcribe') {
        console.log(`AudioRecorder - Expanding transcription card ${id}, checking for content`);
        
        // If we don't have the content in the map, try to get it from the result
        if (!transcriptMap[id] && result.content) {
          console.log(`AudioRecorder - Adding missing transcript to map for ID ${id}`);
          setTranscriptMap(prevMap => ({
            ...prevMap,
            [id]: result.content
          }));
        }
      }
    }
  };

  // Add useEffect to show database errors
  useEffect(() => {
    if (databaseError) {
      toast.error("Database Error", {
        description: databaseError
      });
    }
  }, [databaseError]);

  // Notify parent component about initial results
  useEffect(() => {
    console.log('AudioRecorder - Initial results:', initialResults.length);
    console.log('AudioRecorder - Processed results:', processedResults.length);
    
    if (initialResults.length > 0 && onResultsChange) {
      console.log('AudioRecorder - Notifying parent about initial results');
      onResultsChange(processedResults);
    }
  }, [initialResults, onResultsChange, processedResults]);

  // Set initial results when they change
  useEffect(() => {
    if (initialResults.length > 0) {
      console.log('AudioRecorder - Setting initial results:', initialResults.length);
      setProcessedResults(initialResults);
    }
  }, [initialResults]);

  // Function to handle delete confirmation
  const handleDeleteClick = (id: number, type: string, originalId: string | null) => {
    console.log(`AudioRecorder - Opening delete confirmation for ${type} ID ${id}, original ID: ${originalId}`);
    setItemToDelete({ id, type, originalId });
    setDeleteDialogOpen(true);
  };

  // Function to handle transcript removal confirmation
  const handleTranscriptRemovalClick = (analysisId: string, resultId: number) => {
    console.log(`AudioRecorder - Handling transcript removal click for analysis ID ${analysisId}, result ID ${resultId}`);
    setTranscriptToRemove({ analysisId, resultId });
    setTranscriptRemovalDialogOpen(true);
    
    // Immediately hide the transcript expandable section
    const transcriptEl = document.getElementById(`modal-transcript-${resultId}`);
    if (transcriptEl && !transcriptEl.classList.contains('hidden')) {
      transcriptEl.classList.add('hidden');
    }
  };

  // Function to handle actual deletion
  const handleConfirmDelete = async () => {
    console.log(`AudioRecorder - Confirming delete for ${itemToDelete.type} ID ${itemToDelete.id}`);
    
    if (!itemToDelete.originalId) {
      console.error('Cannot delete item: missing original ID');
      toast.error('Delete failed', { description: 'Could not find the item to delete' });
      return;
    }
    
    try {
      let success = false;
      
      if (itemToDelete.type === 'transcribe') {
        // Mark the transcription as deleted instead of actually deleting it
        success = await deleteTranscription(itemToDelete.originalId);
      } else if (itemToDelete.type === 'summarize' || itemToDelete.type === 'analyze') {
        // For analyses and summaries, actually delete the record
        success = await deleteAnalysis(itemToDelete.originalId);
      }
      
      if (success) {
        // Remove the item from processedResults
        setProcessedResults(prevResults => 
          prevResults.filter(result => result.id !== itemToDelete.id)
        );
        
        // Notify parent component
        if (onResultsChange) {
          onResultsChange(processedResults.filter(result => result.id !== itemToDelete.id));
        }
        
        toast.success('Item deleted successfully');
      } else {
        toast.error('Delete failed', { description: 'Could not delete the item' });
      }
    } catch (error) {
      console.error('Error deleting item:', error);
      toast.error('Delete failed', { description: String(error) });
    } finally {
      setDeleteDialogOpen(false);
    }
  };

  // Initialize originalIdMap from initialResults
  useEffect(() => {
    if (initialResults.length > 0) {
      console.log('AudioRecorder - Initializing originalIdMap from initialResults');
      const newOriginalIdMap: Record<number, string> = {};
      
      initialResults.forEach(result => {
        if (result.originalId) {
          console.log(`AudioRecorder - Adding original ID to map: ID=${result.id}, Original ID=${result.originalId}`);
          newOriginalIdMap[result.id] = result.originalId;
        }
      });
      
      console.log('AudioRecorder - New originalIdMap:', Object.keys(newOriginalIdMap).length, 'entries');
      setOriginalIdMap(newOriginalIdMap);
    }
  }, [initialResults]);

  // Function to get the original transcript from the database for a given analysis
  const fetchTranscriptionForAnalysis = useCallback(async (analysisId: string, resultId?: number) => {
    try {
      console.log(`AudioRecorder - Fetching transcription for analysis ID ${analysisId}`);
      
      // Get the analysis to find the transcription ID
      const analysis = await getAnalysis(analysisId);
      
      // Make sure we have an analysis and a valid transcription ID
      if (!analysis) {
        console.log(`AudioRecorder - No analysis found for ID ${analysisId}`);
        return "No analysis found.";
      }
      
      if (!analysis.transcription_id) {
        console.log(`AudioRecorder - Analysis has no associated transcription ID`);
        return "No associated transcript.";
      }
      
      // Get the transcription details
      const transcription = await getTranscription(analysis.transcription_id);
      
      // Check if we have a valid transcription
      if (!transcription) {
        console.log(`AudioRecorder - No transcription found for ID ${analysis.transcription_id}`);
        return "Transcript not found.";
      }
      
      // Return the transcription content
      console.log(`AudioRecorder - Found transcription content for analysis ID ${analysisId}`);
      return transcription.content || "No content in transcript.";
    } catch (error) {
      console.error("Error fetching transcription for analysis:", error);
      return "Error loading associated transcript.";
    }
  }, [getAnalysis, getTranscription]);

  // Prefetch transcription data for analyses and summaries when component mounts
  useEffect(() => {
    if (initialResults.length > 0) {
      console.log('AudioRecorder - Checking if we need to prefetch any transcription data');
      
      // Get all analyses and summaries that have originalId
      const analysesAndSummaries = initialResults.filter(
        result => (result.type === 'analyze' || result.type === 'summarize') && result.originalId
      );
      
      if (analysesAndSummaries.length > 0) {
        console.log(`AudioRecorder - Found ${analysesAndSummaries.length} analyses/summaries that might need transcription data`);
        
        // Prefetch the first one to avoid loading delay when user first clicks
        const firstItem = analysesAndSummaries[0];
        if (firstItem.originalId) {
          console.log(`AudioRecorder - Prefetching transcription data for analysis ID ${firstItem.originalId}`);
          fetchTranscriptionForAnalysis(firstItem.originalId).catch(err => {
            console.error('Error prefetching transcription data:', err);
          });
        }
      }
    }
  }, [initialResults, fetchTranscriptionForAnalysis]);

  // Function to get the original transcript from the database for a given originalId
  const fetchTranscriptionFromDB = useCallback(async (originalId: string, resultId?: number) => {
    try {
      if (!originalId) {
        console.error("Cannot fetch transcript: originalId is undefined or null");
        return null;
      }
      
      console.log(`AudioRecorder - Attempting to fetch transcription with ID: ${originalId}`);
      
      // Get the transcription from the database
      const transcription = await getTranscription(originalId);
      
      if (!transcription) {
        console.log(`AudioRecorder - Transcription not found or marked as deleted, ID: ${originalId}`);
        // Return a special value to indicate the transcript is deleted
        return "__TRANSCRIPT_DELETED__";
      }
      
      console.log(`AudioRecorder - Successfully fetched transcription from DB, ID: ${originalId}`);
      
      // Use the provided resultId if available, otherwise use lastTranscriptionNumericId
      const mapKey = resultId !== undefined ? resultId : (lastTranscriptionNumericId || 0);
      
      // Update transcript map with the content from the database
      setTranscriptMap(prevMap => ({
        ...prevMap,
        [mapKey]: transcription.content
      }));
      
      return transcription.content;
    } catch (error) {
      console.error("Error fetching transcription:", error);
      
      // Check if it's the specific error we're seeing
      if (error instanceof Error && error.message.includes("multiple (or no) rows returned")) {
        console.log("This is likely because the transcription ID is invalid or the record doesn't exist");
        toast.error("Transcript not found", { 
          description: "The original transcript couldn't be found in the database." 
        });
        return "Original transcript not available.";
      }
      
      toast.error("Failed to load transcript", { 
        description: "Could not fetch the original transcript from the database." 
      });
      return "Error loading transcript.";
    }
  }, [getTranscription, lastTranscriptionNumericId]);

  // Function to handle removing transcription reference
  const handleRemoveTranscriptionReference = async (analysisId: string, resultId: number) => {
    console.log(`AudioRecorder - Removing transcription reference from analysis ID ${analysisId}`);
    
    if (!analysisId) {
      console.error('Cannot remove reference: missing analysis ID');
      toast.error('Operation failed', { description: 'Could not find the analysis' });
      return;
    }
    
    try {
      // First, update the UI immediately to remove the expandable section
      // Set the special value in the transcriptMap to indicate the transcript is deleted
      setTranscriptMap(prevMap => {
        console.log(`AudioRecorder - Setting transcript map for ${resultId} to __TRANSCRIPT_DELETED__`);
        return {
          ...prevMap,
          [resultId]: "__TRANSCRIPT_DELETED__"
        };
      });
      
      // Close the confirmation dialog
      setTranscriptRemovalDialogOpen(false);
      
      // Hide the transcript expandable section if it's open
      const transcriptEl = document.getElementById(`modal-transcript-${resultId}`);
      if (transcriptEl && !transcriptEl.classList.contains('hidden')) {
        transcriptEl.classList.add('hidden');
      }
      
      // Force a re-render of the component by updating the selectedCard
      if (selectedCard && selectedCard.id === resultId) {
        setSelectedCard({...selectedCard});
      }
      
      // Show success toast
      toast.success('Transcript reference removed');
      
      // Then, perform the database operation in the background
      // Get the analysis to find its transcription_id
      const analysis = await getAnalysis(analysisId);
      
      if (!analysis || !analysis.transcription_id) {
        console.error('No transcription reference found');
        return;
      }
      
      // Mark the transcription as deleted
      const success = await deleteTranscription(analysis.transcription_id);
      
      if (!success) {
        console.error('Could not mark the transcript as deleted in the database');
        // We don't show an error toast here since the UI is already updated
      }
    } catch (error) {
      console.error('Error marking transcript as deleted:', error);
      // We don't show an error toast here since the UI is already updated
    }
  };

  // Update selectedCard when modalOpen changes
  useEffect(() => {
    if (modalOpen && selectedCard) {
      console.log(`AudioRecorder - Modal opened for card ID ${selectedCard.id}, type ${selectedCard.type}`);
      console.log(`AudioRecorder - Transcript map for this card:`, transcriptMap[selectedCard.id]);
      console.log(`AudioRecorder - Is transcript deleted:`, transcriptMap[selectedCard.id] === "__TRANSCRIPT_DELETED__");
    }
  }, [modalOpen, selectedCard, transcriptMap]);

  // Function to sort results by date
  const getSortedResults = useCallback(() => {
    return [...processedResults].filter(result => result.type !== "transcribe").sort((a, b) => {
      const dateA = a.date ? new Date(a.date).getTime() : 0;
      const dateB = b.date ? new Date(b.date).getTime() : 0;
      return sortDirection === "asc" ? dateA - dateB : dateB - dateA;
    });
  }, [processedResults, sortDirection]);

  // Toggle sort direction
  const toggleSortDirection = () => {
    setSortDirection(prev => prev === "asc" ? "desc" : "asc");
  };

  // Function to handle translation
  const handleTranslate = async (content: string, language: string, title?: string) => {
    console.log("handleTranslate called with:", { content: content?.substring(0, 50) + "...", language, title });
    
    if (!content || !language || language === "english") {
      console.log("Translation aborted: missing content or language, or language is English");
      return;
    }
    
    setIsTranslating(true);
    console.log("isTranslating set to true");
    
    try {
      // Check if we already have a translation for this content and language
      if (selectedCard && selectedCard.originalId) {
        console.log("Checking for existing translation for:", { originalId: selectedCard.originalId, language });
        const existingTranslation = await getTranslation(selectedCard.originalId, language);
        
        if (existingTranslation) {
          console.log(`AudioRecorder - Found existing translation for ${selectedCard.originalId} in ${language}`);
          const translatedContent = existingTranslation.content;
          const translatedTitle = existingTranslation.title || "";
          
          setTranslatedContent(translatedContent);
          setTranslatedTitle(translatedTitle);
          setTranslationId(existingTranslation.id);
          setSelectedLanguage(language);
          
          // If this is a transcript, update the transcript content
          if (selectedCard.type === 'transcribe') {
            // Update the transcript content
            setTranscriptContent(translatedContent);
            
            // Update the transcript map
            setTranscriptMap(prev => ({
              ...prev,
              [selectedCard.id]: translatedContent
            }));
            
            // Update the processed results
            setProcessedResults(prev => prev.map(item => 
              item.id === selectedCard.id 
                ? { 
                    ...item, 
                    content: translatedContent,
                    title: translatedTitle || item.title
                  } 
                : item
            ));
            
            // Notify parent of changes if callback exists
            if (onResultsChange) {
              onResultsChange(
                processedResults.map(item => 
                  item.id === selectedCard.id 
                    ? { 
                        ...item, 
                        content: translatedContent,
                        title: translatedTitle || item.title
                      } 
                    : item
                )
              );
            }
          }
          
          return;
        } else {
          console.log("No existing translation found, proceeding with new translation");
        }
      } else {
        console.log("No originalId available for selectedCard:", selectedCard);
      }
      
      // Translate the content
      console.log("Calling translateText API with:", { contentLength: content.length, language });
      const translationResult = await translateText(content, language);
      console.log("Translation result:", { success: translationResult.success, contentLength: translationResult.content?.length });
      
      if (translationResult.success && translationResult.content) {
        const translatedContent = translationResult.content;
        setTranslatedContent(translatedContent);
        
        // Translate the title if provided
        let translatedTitleText = "";
        if (title) {
          const titleTranslationResult = await translateText(title, language);
          
          if (titleTranslationResult.success && titleTranslationResult.content) {
            translatedTitleText = titleTranslationResult.content;
            setTranslatedTitle(translatedTitleText);
          }
        }
        
        // Store the translation in the database if authenticated
        if (isAuthenticated && selectedCard && selectedCard.originalId) {
          const originalType = selectedCard.type === 'transcribe' 
            ? 'transcription' 
            : selectedCard.type === 'summarize' 
              ? 'summary' 
              : 'analysis';
          
          const translationData = await createTranslation(
            selectedCard.originalId,
            originalType,
            language,
            translatedContent,
            translatedTitleText || title,
            { source: "recorder" }
          );
          
          if (translationData) {
            console.log("Translation saved to database");
            setTranslationId(translationData.id);
          }
        }
        
        // If this is a transcript, update the transcript content
        if (selectedCard && selectedCard.type === 'transcribe') {
          // Update the transcript content
          setTranscriptContent(translatedContent);
          
          // Update the transcript map
          setTranscriptMap(prev => ({
            ...prev,
            [selectedCard.id]: translatedContent
          }));
          
          // Update the processed results
          setProcessedResults(prev => prev.map(item => 
            item.id === selectedCard.id 
              ? { 
                  ...item, 
                  content: translatedContent,
                  title: translatedTitleText || item.title
                } 
              : item
          ));
          
          // Notify parent of changes if callback exists
          if (onResultsChange) {
            onResultsChange(
              processedResults.map(item => 
                item.id === selectedCard.id 
                  ? { 
                      ...item, 
                      content: translatedContent,
                      title: translatedTitleText || item.title
                    } 
                  : item
              )
            );
          }
          
          // Show success message
          toast.success("Transcript translated", {
            description: "The transcript has been translated and will be used for future operations."
          });
        }
      } else {
        toast.error("Translation failed", { 
          description: translationResult.error || "An unknown error occurred" 
        });
        setTranslatedContent("");
        setTranslatedTitle("");
      }
    } catch (error) {
      console.error("Translation error details:", error);
      toast.error("Translation failed", { 
        description: error instanceof Error ? error.message : "An unknown error occurred" 
      });
      setTranslatedContent("");
      setTranslatedTitle("");
    } finally {
      console.log("Translation process completed, setting isTranslating to false");
      setIsTranslating(false);
    }
  };

  // Load translation when card or language changes
  useEffect(() => {
    const loadTranslation = async () => {
      if (selectedCard && selectedCard.originalId && selectedLanguage !== "english") {
        setIsTranslating(true);
        try {
          const existingTranslation = await getTranslation(selectedCard.originalId, selectedLanguage);
          
          if (existingTranslation) {
            console.log(`AudioRecorder - Found existing translation for ${selectedCard.originalId} in ${selectedLanguage}`);
            const translatedContent = existingTranslation.content;
            const translatedTitle = existingTranslation.title || "";
            
            setTranslatedContent(translatedContent);
            setTranslatedTitle(translatedTitle);
            setTranslationId(existingTranslation.id);
            
            // If this is a transcript, update the transcript content
            if (selectedCard.type === 'transcribe') {
              // Update the transcript content
              setTranscriptContent(translatedContent);
              
              // Update the transcript map
              setTranscriptMap(prev => ({
                ...prev,
                [selectedCard.id]: translatedContent
              }));
              
              // Update the processed results
              setProcessedResults(prev => prev.map(item => 
                item.id === selectedCard.id 
                  ? { 
                      ...item, 
                      content: translatedContent,
                      title: translatedTitle || item.title
                    } 
                  : item
              ));
              
              // Notify parent of changes if callback exists
              if (onResultsChange) {
                onResultsChange(
                  processedResults.map(item => 
                    item.id === selectedCard.id 
                      ? { 
                          ...item, 
                          content: translatedContent,
                          title: translatedTitle || item.title
                        } 
                      : item
                  )
                );
              }
            }
          } else {
            // No translation found, reset state
            setTranslatedContent("");
            setTranslatedTitle("");
            setTranslationId(null);
          }
        } catch (error) {
          console.error("Error loading translation:", error);
          setTranslatedContent("");
          setTranslatedTitle("");
          setTranslationId(null);
        } finally {
          setIsTranslating(false);
        }
      } else {
        // Reset translation state when switching back to English
        setTranslatedContent("");
        setTranslatedTitle("");
        setTranslationId(null);
      }
    };
    
    loadTranslation();
  }, [selectedCard, selectedLanguage, getTranslation, onResultsChange, processedResults]);

  // Function to copy content to clipboard
  const copyToClipboard = () => {
    const contentToCopy = translatedContent && selectedLanguage !== "english" 
      ? translatedContent 
      : selectedCard?.content.includes("This is a")
        ? selectedCard.content.replace(/^This is a (summary|analysis) of the audio recording\.\s+/, "")
        : selectedCard?.content;
    
    if (contentToCopy) {
      navigator.clipboard.writeText(contentToCopy)
        .then(() => {
          setCopySuccess(true);
          setTimeout(() => setCopySuccess(false), 2000);
        })
        .catch(err => {
          console.error('Failed to copy text: ', err);
        });
    }
  };

  return (
    <>
      {processedResults.length > 0 && (
        <div className="mx-auto px-2 z-[60] overflow-y-auto custom-scrollbar" style={{ maxHeight: 'calc(100vh - 100px)' }}>
          <div className="flex justify-center mb-4 space-x-2">
            <Button
              variant="ghost"
              size="sm"
              className="h-8 px-3 bg-white/10 backdrop-blur-md rounded-lg border border-white/20 text-white/70 hover:text-white/90 hover:bg-white/15 flex items-center space-x-1"
              onClick={toggleSortDirection}
            >
              <span>Sort by Date</span>
              {sortDirection === "asc" ? (
                <ArrowUp className="h-4 w-4 ml-1" />
              ) : (
                <ArrowDown className="h-4 w-4 ml-1" />
              )}
            </Button>
            <div className="bg-white/10 backdrop-blur-md rounded-lg border border-white/20 flex overflow-hidden">
              <Button
                variant="ghost"
                size="icon"
                className={`h-8 w-8 rounded-none text-white/70 hover:text-white ${viewMode === 'card' ? 'bg-white/20' : ''} hover:bg-white/15`}
                onClick={() => setViewMode("card")}
                title="Card View"
              >
                <Grid className="h-4 w-4" />
              </Button>
              <Button
                variant="ghost"
                size="icon"
                className={`h-8 w-8 rounded-none text-white/70 hover:text-white ${viewMode === 'list' ? 'bg-white/20' : ''} hover:bg-white/15`}
                onClick={() => setViewMode("list")}
                title="List View"
              >
                <List className="h-4 w-4" />
              </Button>
            </div>
          </div>
          
          {viewMode === "card" ? (
            <div className="flex justify-center pb-20 mt-2">
              <div className="max-w-6xl w-full">
                <div className="grid grid-cols-1 sm:grid-cols-1 md:grid-cols-2 lg:grid-cols-3 xl:grid-cols-4 gap-8">
                  {getSortedResults().map(result => (
                    <div key={result.id} className="w-full">
                      <div 
                        className="w-full h-[280px] bg-white/10 backdrop-blur-md rounded-lg border border-white/20 shadow-lg overflow-hidden flex flex-col relative"
                      >
                        <div className="p-4 border-b border-white/20 bg-white/5 flex items-center">
                          <Button
                            variant="ghost"
                            size="icon"
                            className="h-6 w-6 rounded-full bg-white/10 hover:bg-red-500/20 text-white/70 hover:text-red-400 flex-shrink-0 mr-2"
                            onClick={(e) => {
                              e.stopPropagation();
                              // Get the original ID from the result or from the originalIdMap
                              const originalId = result.originalId || originalIdMap[result.id] || null;
                              handleDeleteClick(result.id, result.type, originalId);
                            }}
                            disabled={result.generating}
                          >
                            <Trash2 className="h-3 w-3" />
                          </Button>
                          <h4 className="font-medium text-white text-base truncate flex-1">
                            {result.generating ? 
                              (result.type === "summarize" ? "Generating Summary..." : "Generating Analysis...") : 
                              (result.title || (result.type === "summarize" ? "Summary" : "Analysis"))}
                          </h4>
                          <Button
                            variant="ghost"
                            size="icon"
                            className="h-6 w-6 rounded-full bg-white/10 hover:bg-white/20 text-white/70 hover:text-white flex-shrink-0 ml-2"
                            onClick={() => toggleCardExpanded(result.id)}
                            disabled={result.generating}
                          >
                            <Maximize2 className="h-3 w-3" />
                          </Button>
                        </div>
                        <div className="p-4 flex-1 overflow-y-auto custom-scrollbar text-sm text-white/90">
                          {result.generating ? (
                            <div className="flex items-center justify-center h-full">
                              <div className="animate-pulse">Generating...</div>
                            </div>
                          ) : (
                            <>
                              <div className="whitespace-pre-line line-clamp-7">
                                {result.content.includes("This is a") ? 
                                  result.content.replace(/^This is a (summary|analysis) of the audio recording\.\s+/, "") : 
                                  result.content}
                              </div>
                              <div className="text-xs text-white/50 absolute bottom-3 left-3 pt-5">
                                <span>{new Date(result.date || Date.now()).toLocaleDateString('en-US', { 
                                  month: 'short', 
                                  day: 'numeric',
                                  hour: '2-digit',
                                  minute: '2-digit'
                                })}</span>
                              </div>
                            </>
                          )}
                        </div>
                      </div>
                    </div>
                  ))}
                </div>
              </div>
            </div>
          ) : (
            <div className="w-full mx-auto pb-40 custom-scrollbar">
              <div className="bg-white/10 backdrop-blur-md rounded-lg border border-white/20 shadow-lg overflow-hidden">
                <table className="w-full text-white/90">
                  <thead>
                    <tr className="border-b border-white/20 bg-white/5">
                      <th className="py-3 px-6 text-left font-medium">Title</th>
                      <th className="py-3 px-6 text-left font-medium">Type</th>
                      <th className="py-3 px-6 text-left font-medium">
                        <div className="flex items-center">
                          <span>Date</span>
                          <button 
                            className="ml-1 text-white/50 hover:text-white/90 inline-flex hover:bg-white/15 rounded-full p-0.5"
                            onClick={toggleSortDirection}
                          >
                            {sortDirection === "asc" ? (
                              <ArrowUp className="h-3 w-3" />
                            ) : (
                              <ArrowDown className="h-3 w-3" />
                            )}
                          </button>
                        </div>
                      </th>
                      <th className="py-3 px-6 text-right font-medium">Actions</th>
                    </tr>
                  </thead>
                  <tbody>
                    {getSortedResults().map(result => (
                      <tr key={result.id} className="border-b border-white/10 hover:bg-white/5">
                        <td className="py-3 px-6">
                          {result.generating ? 
                            (result.type === "summarize" ? "Generating Summary..." : "Generating Analysis...") : 
                            (result.title || (result.type === "summarize" ? "Summary" : "Analysis"))}
                        </td>
                        <td className="py-3 px-6">
                          {result.type === "summarize" ? "Summary" : "Analysis"}
                        </td>
                        <td className="py-3 px-6">
                          {new Date(result.date || Date.now()).toLocaleDateString('en-US', { 
                            year: 'numeric',
                            month: 'short', 
                            day: 'numeric',
                            hour: '2-digit',
                            minute: '2-digit'
                          })}
                        </td>
                        <td className="py-3 px-6 text-right">
                          <div className="flex items-center justify-end space-x-2">
                            <Button
                              variant="ghost"
                              size="icon"
                              className="h-6 w-6 rounded-full bg-white/10 hover:bg-white/20 text-white/70 hover:text-white"
                              onClick={() => toggleCardExpanded(result.id)}
                              disabled={result.generating}
                            >
                              <Maximize2 className="h-3 w-3" />
                            </Button>
                            <Button
                              variant="ghost"
                              size="icon"
                              className="h-6 w-6 rounded-full bg-white/10 hover:bg-red-500/20 text-white/70 hover:text-red-400"
                              onClick={() => {
                                const originalId = result.originalId || originalIdMap[result.id] || null;
                                handleDeleteClick(result.id, result.type, originalId);
                              }}
                              disabled={result.generating}
                            >
                              <Trash2 className="h-3 w-3" />
                            </Button>
                          </div>
                        </td>
                      </tr>
                    ))}
                  </tbody>
                </table>
              </div>
            </div>
          )}
        </div>
      )}

      {/* Delete confirmation dialog */}
      <AlertDialog open={deleteDialogOpen} onOpenChange={setDeleteDialogOpen}>
        <AlertDialogContent className="bg-gray-800 border border-gray-700 text-white">
          <AlertDialogHeader>
            <AlertDialogTitle>Are you sure?</AlertDialogTitle>
            <AlertDialogDescription className="text-gray-300">
              This will permanently delete this {itemToDelete.type === 'transcribe' ? 'transcription' : 
                itemToDelete.type === 'summarize' ? 'summary' : 'analysis'}.
              This action cannot be undone.
            </AlertDialogDescription>
          </AlertDialogHeader>
          <AlertDialogFooter>
            <AlertDialogCancel className="bg-gray-700 text-white hover:bg-gray-600">Cancel</AlertDialogCancel>
            <AlertDialogAction 
              className="bg-red-600 text-white hover:bg-red-700" 
              onClick={handleConfirmDelete}
            >
              Delete
            </AlertDialogAction>
          </AlertDialogFooter>
        </AlertDialogContent>
      </AlertDialog>

      {/* Transcript removal confirmation dialog */}
      <AlertDialog open={transcriptRemovalDialogOpen} onOpenChange={setTranscriptRemovalDialogOpen}>
        <AlertDialogContent className="bg-gray-800 border border-gray-700 text-white">
          <AlertDialogHeader>
            <AlertDialogTitle>Remove transcript reference?</AlertDialogTitle>
            <AlertDialogDescription className="text-gray-300">
              This will remove the transcript reference from this item.
              The transcript will be marked as deleted but can be recovered by an administrator if needed.
            </AlertDialogDescription>
          </AlertDialogHeader>
          <AlertDialogFooter>
            <AlertDialogCancel className="bg-gray-700 text-white hover:bg-gray-600">Cancel</AlertDialogCancel>
            <AlertDialogAction 
              className="bg-red-600 text-white hover:bg-red-700" 
              onClick={() => handleRemoveTranscriptionReference(transcriptToRemove.analysisId, transcriptToRemove.resultId)}
            >
              Remove
            </AlertDialogAction>
          </AlertDialogFooter>
        </AlertDialogContent>
      </AlertDialog>

      <Card className={`fixed bottom-4 left-1/2 transform -translate-x-1/2 ${isMinimized ? 'w-auto' : 'w-full max-w-md'} overflow-hidden bg-white/10 backdrop-blur-md border-0 shadow-xl z-[100] transition-all duration-300`}>
        <div className="absolute top-2 right-2 z-10">
          <Button
            variant="ghost"
            size="icon"
            className="h-6 w-6 rounded-full bg-white/10 hover:bg-white/20 text-white/70 hover:text-white"
            onClick={() => setIsMinimized(!isMinimized)}
          >
            {isMinimized ? <Maximize2 className="h-3 w-3" /> : <X className="h-3 w-3" />}
          </Button>
        </div>
        {isMinimized ? (
          <div className="p-3 flex items-center space-x-3">
            <Button
              variant="default"
              style={getRecordingButtonStyles()}
              className="rounded-full p-0 flex items-center justify-center h-10 w-10"
              onClick={() => {
                if (isRecording) {
                  stopRecording();
                } else {
                  setIsMinimized(false);
                  startRecording();
                }
              }}
            >
              {isRecording ? <Square className="h-4 w-4" /> : <Mic className="h-4 w-4" />}
            </Button>
            <span className="text-xs text-white/80 font-medium">
              {isRecording ? formatTimeRemaining() : "Record Audio"}
            </span>
          </div>
        ) : (
        <CardContent className="p-5">
          <Tabs defaultValue="record" className="w-full">
            <TabsList className="grid w-full grid-cols-2 mb-6 bg-white/10 p-1 rounded-lg">
              <TabsTrigger
                value="record"
                className="data-[state=active]:bg-white/20 data-[state=active]:text-white data-[state=active]:shadow-md text-white/70"
              >
                Record
              </TabsTrigger>
              <TabsTrigger
                value="upload"
                className="data-[state=active]:bg-white/20 data-[state=active]:text-white data-[state=active]:shadow-md text-white/70"
              >
                Upload
              </TabsTrigger>
            </TabsList>

            <TabsContent value="record" className="space-y-5">
              {/* Recording controls */}
              <div className="space-y-4">
                {/* Timer display - show time remaining when recording, or elapsed time after recording */}
                {isRecording ? (
                  <div className="text-center">
                    <div className="text-3xl font-mono font-bold text-white">
                      {formatTimeRemaining()}
                    </div>
                    <div className="text-xs text-white/70 mt-1">
                      {isAuthenticated 
                        ? "Premium: 10 minute recording limit" 
                        : "Free: 5 minute recording limit"}
                    </div>
                  </div>
                ) : isPostRecording && (
                  <div className="text-center">
                    <span className="text-3xl font-mono font-bold text-white">
                      {formatTime(recordingTime)}
                    </span>
                  </div>
                )}

                {/* Control buttons */}
                <div className="flex justify-center gap-4">
                  {isRecording ? (
                    <Button
                      variant="destructive"
                      style={getStopButtonStyles()}
                      className="rounded-full p-0 flex items-center justify-center"
                      onClick={stopRecording}
                    >
                      <Square className="h-6 w-6" />
                    </Button>
                  ) : isPostRecording ? (
                    <div className="flex gap-3">
                      <Button
                        variant="outline"
                        size="icon"
                        className="rounded-full w-12 h-12 border-white/20 bg-white/10 text-white hover:bg-white/20 hover:text-white"
                        onClick={resetRecorder}
                      >
                        <Trash2 className="h-5 w-5" />
                      </Button>
                      <Button
                        variant="outline"
                        size="icon"
                        className="rounded-full w-12 h-12 border-white/20 bg-white/10 text-white hover:bg-white/20 hover:text-white"
                        onClick={togglePlayRecorded}
                      >
                        {isPlaying ? <Pause className="h-5 w-5" /> : <Play className="h-5 w-5" />}
                      </Button>
                      <Button
                        variant="outline"
                        size="icon"
                        className="rounded-full w-12 h-12 border-white/20 bg-white/10 text-white hover:bg-white/20 hover:text-white"
                        onClick={resetRecorder}
                      >
                        <PlusCircle className="h-5 w-5" />
                      </Button>
                    </div>
                  ) : (
                    <div className="flex flex-col items-center">
                      <Button
                        variant="default"
                        style={getRecordingButtonStyles()}
                        className="rounded-full p-0 flex items-center justify-center mb-2"
                        onClick={startRecording}
                      >
                        <Mic className="h-6 w-6" />
                      </Button>
                      <span className="text-xs text-white/60">Tap to record</span>
                    </div>
                  )}
                </div>
              </div>

              {/* AI Processing section - only show after recording */}
              {isPostRecording && audioURL && (
                <div className="space-y-4 mt-6 pt-6 border-t border-white/20">
                  <Select
                    value={selectedAiAction}
                    onValueChange={setSelectedAiAction}
                  >
                    <SelectTrigger className="w-full h-12 text-white text-base bg-white/10 border-white/20 focus:ring-white/30">
                      <SelectValue placeholder="Select AI action" />
                      <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round" className="ml-2">
                        <path d="m6 9 6 6 6-6"/>
                      </svg>
                    </SelectTrigger>
                    <SelectContent className="bg-slate-800 border-white/20 text-white">
                      <SelectItem value="summarize" className="text-base focus:bg-white/10 focus:text-white">Summarize</SelectItem>
                      <SelectItem value="analyze" className="text-base focus:bg-white/10 focus:text-white">Analyze</SelectItem>
                    </SelectContent>
                  </Select>

                  <Button
                    variant="default"
                    className="w-full bg-gradient-to-r from-indigo-500 to-purple-600 hover:from-indigo-600 hover:to-purple-700 text-white h-12 text-base"
                    disabled={aiProcessing}
                    onClick={processWithAI}
                  >
                    {aiProcessing ? "Processing..." : `${selectedAiAction.charAt(0).toUpperCase() + selectedAiAction.slice(1)} Audio`}
                  </Button>
                  
                  {/* Display transcript in the recorder card */}
                  <div className="mt-4 p-4 pb-0 bg-white/10 rounded-lg border border-white/20 text-sm text-white/90">
                    <h4 className="font-medium text-white mb-2">Transcript</h4>
                    <div className="whitespace-pre-line max-h-60 overflow-y-auto">
                      {aiProcessing ? (
                        <div className="flex items-center justify-center py-4">
                          <div className="animate-pulse">Generating transcript...</div>
                        </div>
                      ) : (
                        getTranscriptContent(lastTranscriptionNumericId || 0)
                      )}
                    </div>
                    
                    <div className="px-4 py-3 mt-4 border-t border-white/10 bg-white/5 text-xs text-white/60 flex justify-between items-center -mx-4 rounded-b-lg">
                      <span>{new Date().toLocaleDateString('en-US', { 
                        year: 'numeric',
                        month: 'short', 
                        day: 'numeric',
                        hour: '2-digit',
                        minute: '2-digit'
                      })}</span>
                      
                      <div className="flex items-center space-x-3">
                        <Select defaultValue="english">
                          <SelectTrigger className="h-6 w-24 text-xs bg-white/10 border-white/20 [&_svg]:text-white">
                            <SelectValue placeholder="English" />
                          </SelectTrigger>
                          <SelectContent>
                            <SelectItem value="english">English</SelectItem>
                            <SelectItem value="dutch">Dutch</SelectItem>
                            <SelectItem value="german">German</SelectItem>
                            <SelectItem value="french">French</SelectItem>
                            <SelectItem value="spanish">Spanish</SelectItem>
                          </SelectContent>
                        </Select>
                        
                        <Button 
                          variant="outline" 
                          size="sm" 
                          className="h-6 text-xs bg-white/70 text-gray-800 hover:bg-white/90 border-white/20"
                          onClick={() => {
                            console.log("Translate button clicked", { 
                              selectedCard: selectedCard?.id,
                              content: selectedCard?.content?.substring(0, 50) + "...", 
                              language: selectedLanguage
                            });
                            handleTranslate(selectedCard?.content || "", selectedLanguage, selectedCard?.title);
                          }}
                          disabled={isTranslating || selectedLanguage === "english"}
                        >
                          {isTranslating ? "Translating..." : "Translate"}
                        </Button>
                      </div>
                    </div>
                  </div>
                </div>
              )}
            </TabsContent>

            <TabsContent value="upload" className="space-y-5">
              {!uploadedFile ? (
                <div className="flex flex-col items-center justify-center p-6 border-2 border-dashed border-white/20 rounded-lg bg-white/5">
                  <Upload className="h-8 w-8 text-white/50 mb-2" />
                  <p className="text-sm text-white/70 mb-4 text-center">
                    Upload an audio or video file to process with AI
                  </p>
                  <input
                    type="file"
                    id="audio-upload"
                    accept="audio/*,video/mp4"
                    className="hidden"
                    onChange={handleFileUpload}
                  />
                  <label
                    htmlFor="audio-upload"
                    className="inline-flex items-center justify-center px-4 py-2 bg-white/20 text-white text-sm font-medium rounded-md hover:bg-white/30 cursor-pointer transition-colors"
                  >
                    Select File
                  </label>
                </div>
              ) : (
                <div className="p-4 bg-white/10 rounded-lg border border-white/20">
                  <div className="flex items-center justify-between mb-4">
                    <div>
                      <h3 className="font-medium text-white">{uploadedFile.name}</h3>
                      <p className="text-xs text-white/60">
                        {(uploadedFile.size / 1024 / 1024).toFixed(2)} MB
                      </p>
                    </div>
                    <Button
                      variant="outline"
                      size="icon"
                      className="h-8 w-8 border-white/20 bg-white/10 text-white hover:bg-white/20 hover:text-white"
                      onClick={togglePlayUploaded}
                    >
                      {isUploadedPlaying ? <Pause className="h-4 w-4" /> : <Play className="h-4 w-4" />}
                    </Button>
                  </div>
                  
                  {/* Display transcript for uploaded file */}
                  <div className="mt-4 p-4 bg-white/10 rounded-lg border border-white/20 text-sm text-white/90">
                    <h4 className="font-medium mb-2 text-white">Transcript</h4>
                    <div className="whitespace-pre-line max-h-60 overflow-y-auto">
                      {aiProcessing ? (
                        <div className="flex items-center justify-center py-4">
                          <div className="animate-pulse">Generating transcript...</div>
                        </div>
                      ) : (
                        getTranscriptContent(lastTranscriptionNumericId || 0)
                      )}
                    </div>
                  </div>
                  
                  {/* AI Processing options for uploaded file */}
                  <div className="space-y-4 mt-6 pt-6 border-t border-white/20">
                    <Select
                      value={selectedAiAction}
                      onValueChange={setSelectedAiAction}
                    >
                      <SelectTrigger className="w-full h-12 text-white text-base bg-white/10 border-white/20 focus:ring-white/30">
                        <SelectValue placeholder="Select AI action" />
                        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round" className="ml-2">
                          <path d="m6 9 6 6 6-6"/>
                        </svg>
                      </SelectTrigger>
                      <SelectContent className="bg-slate-800 border-white/20 text-white">
                        <SelectItem value="summarize" className="text-base focus:bg-white/10 focus:text-white">Summarize</SelectItem>
                        <SelectItem value="analyze" className="text-base focus:bg-white/10 focus:text-white">Analyze</SelectItem>
                      </SelectContent>
                    </Select>

                    <Button
                      variant="default"
                      className="w-full bg-gradient-to-r from-indigo-500 to-purple-600 hover:from-indigo-600 hover:to-purple-700 text-white h-12 text-base"
                      disabled={aiProcessing}
                      onClick={processWithAI}
                    >
                      {aiProcessing ? "Processing..." : `${selectedAiAction.charAt(0).toUpperCase() + selectedAiAction.slice(1)} Audio`}
                    </Button>
                  </div>
                </div>
              )}
            </TabsContent>
          </Tabs>
        </CardContent>
        )}
        {/* Only show footer with save button after recording and when not minimized */}
        {isPostRecording && audioURL && !isMinimized && (
          <CardFooter className="px-5 py-3 border-t border-white/20 bg-white/5 text-xs text-white/60">
            <div className="w-full flex justify-between items-center">
              <span>Audio Recorder</span>
              <a
                href="#"
                className="text-white/80 hover:text-white hover:underline transition-colors"
                onClick={(e) => {
                  e.preventDefault()
                  if (audioURL) {
                    const a = document.createElement("a")
                    a.href = audioURL
                    const extension = getFileExtensionFromMimeType(currentMimeType);
                    a.download = `recording.${extension}`
                    a.click()
                  }
                }}
              >
                <Save className="h-4 w-4 inline-block mr-1" />
                Save Recording
              </a>
            </div>
          </CardFooter>
        )}
        {/* Audio element for playback */}
        <audio 
          ref={audioRef} 
          className="hidden" 
          controls={false}
          preload="auto"
          onError={(e) => console.error("Audio error:", e)}
        />
      </Card>

      {/* Modal for expanded card */}
      <Dialog open={modalOpen} onOpenChange={setModalOpen}>
        <DialogContent className="bg-white/10 backdrop-blur-md border border-white/20 text-white max-w-4xl min-h-[450px] max-h-[80vh] flex flex-col p-0 rounded-lg overflow-hidden shadow-lg">
          <DialogHeader className="sr-only">
            <DialogTitle>
              {selectedCard?.title || (selectedCard?.type === "summarize" ? "Summary" : "Analysis")}
            </DialogTitle>
          </DialogHeader>
          <div className="p-3 border-b border-white/20 bg-white/5 flex items-center">
            <h4 className="font-medium text-white text-base truncate flex-1">
              {translatedTitle && selectedLanguage !== "english" 
                ? translatedTitle 
                : selectedCard?.title || (selectedCard?.type === 'transcribe' 
                  ? 'Transcript' 
                  : selectedCard?.type === 'summarize' 
                    ? 'Summary' 
                    : 'Analysis')}
            </h4>
            <DialogClose className="h-6 w-6 rounded-full bg-white/10 hover:bg-white/20 text-white/70 hover:text-white flex-shrink-0 ml-2 flex items-center justify-center">
              <X className="h-3 w-3" />
            </DialogClose>
          </div>
          <div className="p-3 flex-1 overflow-y-auto custom-scrollbar text-sm text-white/90 flex flex-col">
            {selectedCard ? (
              <>
                <div className="whitespace-pre-line flex-1">
                  {isTranslating ? (
                    <div className="flex items-center justify-center py-8">
                      <div className="animate-pulse">Translating...</div>
                    </div>
                  ) : translatedContent && selectedLanguage !== "english" ? (
                    <div className="whitespace-pre-line">
                      {translatedContent}
                    </div>
                  ) : (
                    <div className="whitespace-pre-line">
                      {selectedCard.content.includes("This is a") ? 
                        selectedCard.content.replace(/^This is a (summary|analysis) of the audio recording\.\s+/, "") : 
                        selectedCard.content}
                    </div>
                  )}
                </div>
                
                <div className="mt-4">
                  {/* Only show the Original Transcript section when we have a valid transcriptionId */}
                  {selectedCard.type !== 'transcribe' && 
                   ((selectedCard.originalId) || 
                    (originalIdMap[selectedCard.id])) && (
                    <>
                      <div 
                        className="flex items-center cursor-pointer p-2 hover:bg-white/5 rounded-md transition-colors"
                        onClick={(e) => {
                          e.stopPropagation();
                          
                          // Toggle the visibility of the transcript element
                          const transcriptEl = document.getElementById(`modal-transcript-${selectedCard.id}`);
                          if (transcriptEl) {
                            transcriptEl.classList.toggle('hidden');
                          }
                          
                          // Check if we have a transcript
                          if (!transcriptMap[selectedCard.id]) {
                            console.log(`AudioRecorder - Need to fetch transcript for card ${selectedCard.id}`);
                            
                            // Set a loading state while fetching
                            setTranscriptMap(prevMap => ({
                              ...prevMap,
                              [selectedCard.id]: "Loading transcript..."
                            }));
                            
                            // For transcripts, we can directly use the content
                            if (selectedCard.type === 'transcribe') {
                              console.log(`AudioRecorder - Using direct content for transcript card ${selectedCard.id}`);
                              setTranscriptMap(prevMap => ({
                                ...prevMap,
                                [selectedCard.id]: selectedCard.content
                              }));
                            }
                            else if ((selectedCard.type === 'summarize' || selectedCard.type === 'analyze') && 
                                    (selectedCard.originalId || originalIdMap[selectedCard.id])) {
                              const originalId = selectedCard.originalId || originalIdMap[selectedCard.id];
                              console.log(`AudioRecorder - Fetching transcript for analysis ID ${originalId}`);
                              // For summaries and analyses, we need to get the transcription via the analysis record
                              fetchTranscriptionForAnalysis(originalId, selectedCard.id)
                                .then(content => {
                                  if (content) {
                                    setTranscriptMap(prevMap => ({
                                      ...prevMap,
                                      [selectedCard.id]: content
                                    }));
                                  }
                                });
                            }
                          }
                        }}
                      >
                        <h5 className="font-medium text-white/90 text-sm flex-1 truncate">Original Transcript</h5>
                        <ChevronDown className="h-4 w-4 text-white/70 flex-shrink-0 ml-2" />
                      </div>
                      <div id={`modal-transcript-${selectedCard.id}`} className="p-3 bg-white/5 rounded-lg hidden">
                        <div className="whitespace-pre-line text-white/80 text-xs max-h-[200px] overflow-y-auto custom-scrollbar">
                          {transcriptMap[selectedCard.id] || "Loading transcript..."}
                        </div>
                      </div>
                    </>
                  )}
                </div>
              </>
            ) : (
              <div className="flex items-center justify-center h-full">
                <div className="animate-pulse">Loading...</div>
              </div>
            )}
          </div>
          
          {selectedCard && (
            <div className="px-4 py-3 border-t border-white/10 bg-white/5 text-xs text-white/60 flex justify-between items-center">
              <span>{new Date(selectedCard.date || Date.now()).toLocaleDateString('en-US', { 
                year: 'numeric',
                month: 'short', 
                day: 'numeric',
                hour: '2-digit',
                minute: '2-digit'
              })}</span>
              
              <div className="flex items-center space-x-3">
                <Button
                  variant="ghost"
                  size="sm"
                  className="h-6 w-6 p-0 text-white/70 hover:text-white hover:bg-white/10"
                  onClick={copyToClipboard}
                  title="Copy to clipboard"
                >
                  {copySuccess ? (
                    <span className="text-green-400 text-xs">Copied!</span>
                  ) : (
                    <Copy className="h-3.5 w-3.5" />
                  )}
                </Button>
                
                <Select 
                  defaultValue="english" 
                  value={selectedLanguage}
                  onValueChange={(value) => setSelectedLanguage(value)}
                >
                  <SelectTrigger className="h-6 w-24 text-xs bg-white/10 border-white/20 [&_svg]:text-white">
                    <SelectValue placeholder="English" />
                  </SelectTrigger>
                  <SelectContent>
                    <SelectItem value="english">English</SelectItem>
                    <SelectItem value="dutch">Dutch</SelectItem>
                    <SelectItem value="german">German</SelectItem>
                    <SelectItem value="french">French</SelectItem>
                    <SelectItem value="spanish">Spanish</SelectItem>
                  </SelectContent>
                </Select>
                
                <Button 
                  variant="outline" 
                  size="sm" 
                  className="h-6 text-xs bg-white/70 text-gray-800 hover:bg-white/90 border-white/20"
                  onClick={() => {
                    console.log("Translate button clicked", { 
                      selectedCard: selectedCard?.id,
                      content: selectedCard?.content?.substring(0, 50) + "...", 
                      language: selectedLanguage
                    });
                    handleTranslate(selectedCard?.content || "", selectedLanguage, selectedCard?.title);
                  }}
                  disabled={isTranslating || selectedLanguage === "english"}
                >
                  {isTranslating ? "Translating..." : "Translate"}
                </Button>
              </div>
            </div>
          )}
        </DialogContent>
      </Dialog>
    </>
  )
}

